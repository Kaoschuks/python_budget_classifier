{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing our budget with Excel and machine learning\n",
    "\n",
    "\n",
    "A little over a year ago my girlfriend Lisette and I moved in together. A big part of living together was getting used to managing a budget, and knowing where our money went. Lisette made one of the coolest Excel spreadsheets I ever saw, the only thing we needed to do was... actually fill in what expense belongs to what category. This is where things went wrong...\n",
    "\n",
    "Every month we have about 100 shared expenses, and labeling them turned out to be a boring job we both didn't want to do (and thus ignored for the last 10 months...). Last weekend I made an attempt at automating this task using the power of machine learning!\n",
    "\n",
    "The first step to training a classifier is getting your training data! My bank gives you the option to download a spreadsheet with all (unlabeled) expenses. I imported this into a Google spreadsheet and added two columns: one with my own (optional) labels and one for the computer-generated labels. \n",
    "\n",
    "![extra labels](http://www.pinchofintelligence.com/wp-content/uploads/2017/12/excelextra.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Excel data into Python\n",
    "Although writing a classifier in Excel is probably possible I used Python with the NLTK and SKLearn library. To do this I needed to get all transactions and labels I added in my Jupyter Notebook. Thanks to [Greg Baugues](https://twitter.com/greggyb) this turned out to be surprisingly easy! His [blog post](https://www.twilio.com/blog/2017/02/an-easy-way-to-read-and-write-to-a-google-spreadsheet-in-python.html) was a great help, and made this process pretty smooth. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('google_account.json', ['https://spreadsheets.google.com/feeds'])\n",
    "client = gspread.authorize(creds)\n",
    "temp = client.open(\"rolands budgetvariant\")\n",
    "sheet = temp.worksheet(\"ALLES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For each transaction, I made a feature vector with a boolean for each of the most common words in the transaction. I made separate lists for words in the description, the number of the account money was transferred to, and whether we receive money or not.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def get_freq_dist_for_sheet(sheet, key, max_words=30):\n",
    "    records = sheet.get_all_records()\n",
    "    words = list()\n",
    "    for record in records:\n",
    "        words.extend(w.lower() for w in record[key].split())\n",
    "    \n",
    "    all_words = nltk.FreqDist(words)\n",
    "    word_features = list(all_words)[:max_words]\n",
    "    return word_features\n",
    "\n",
    "interesting_features = [\"Naam / Omschrijving\", \"Tegenrekening\", \"Af Bij\", \"Mededelingen\"]\n",
    "freq_dists = dict()\n",
    "for feature in interesting_features:\n",
    "    freq_dists[feature] = get_freq_dist_for_sheet(sheet, feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def record_features(record, key, doc_features): \n",
    "    document_words = set(w.lower() for w in record[key].split()) \n",
    "    features = {}\n",
    "    for word in doc_features:\n",
    "        features['contains({},{})'.format(key,word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "def all_record_features(record):\n",
    "    input_data = dict()\n",
    "    for categorie_name in freq_dists:\n",
    "        ## dict.update means that you merge dictionaries\n",
    "        input_data.update(record_features(record, categorie_name, freq_dists[categorie_name]))\n",
    "    return input_data\n",
    "\n",
    "def get_traindata(sheet):\n",
    "    records = sheet.get_all_records()\n",
    "    traindata = list()\n",
    "    for record in records:\n",
    "        if record[\"Categorie\"]:\n",
    "            input_data = all_record_features(record)\n",
    "            traindata.append((input_data, record[\"Categorie\"]))\n",
    "    return traindata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 365 entries\n",
      "{'reizen', 'inleg roland', 'overig', 'benzine', 'goede doelen', 'sport', 'uit eten', 'electriciteit', 'internet', 'huur', 'zorgverzekering roland', 'water', 'verzekering roland', 'sport lisette', 'wegenbelasting', 'tanken', 'cash', 'parkeren', 'openbaar vervoer', 'auto', 'abonnementen', 'verzekering auto', 'boodschappen', 'inleg lisette', 'waterschapsbelasting'}\n"
     ]
    }
   ],
   "source": [
    "training_data = get_traindata(sheet)\n",
    "all_labels = set([x[1] for x in training_data])\n",
    "print(\"Training with \" + str(len(training_data)) + \" entries\")\n",
    "print(all_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After selecting all the transactions I labeled, and converting them to these feature vectors I could select and train a classifier! I decided to go for a simple decision tree. Not only did I expect this to work reasonably well for my features (only recognizing where I do groceries and who I pay my rent to would remove 80% of transactions I normally have to label!). Conveniently the NLTK library I used to create the frequency distribution also contains a class that allows you to import any SKLearn classifier. This reduced training to one line of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "classifier = SklearnClassifier(tree.DecisionTreeClassifier(), sparse=False).train(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the decision tree\n",
    "The SKLearn tree classifier has a function to write the decision tree as a graphviz file. This function requires the classifier NLTK created, the feature names, and the class labels. Getting these required a bit of documentation reading as there are no clear functions to get these (and there is no way to know what the classifier did with your data). Eventually, the following code was able to get what I needed. Python can even write the whole tree itself if you install and import the graphviz library. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'budget_decisiontree.pdf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "\n",
    "dot_data = tree.export_graphviz(classifier._clf, out_file=None, \n",
    "                         feature_names=classifier._vectorizer.get_feature_names(),  \n",
    "                         class_names=classifier.labels(),  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"budget_decisiontree\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a part of the decision tree the algorithm generated. It correctly discovered that I do my grocery shopping at the \"Albert Heijn\" (https://www.youtube.com/watch?v=GiZJa_Ctkr4), where I rent my apartment, where my internet money goes to, and much more!\n",
    "\n",
    "![result](http://www.pinchofintelligence.com/wp-content/uploads/2017/12/subparttree.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling data\n",
    "And now the most important part of this project: classify each of my transactions! As described at the start of this article I added a column for the computer prediction. The Google Sheets API allows you to write a single cell at a time which for some reason takes around a second per edit. Although it's annoying if you try to iterate quickly, it gives some cool visualizations while your algorithm is working!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records = sheet.get_all_records()\n",
    "for row, record in enumerate(records):\n",
    "    try:\n",
    "        row += 2 # rows start at 1... first row is a header\n",
    "        input_data = all_record_features(record)\n",
    "        but = classifier.classify(input_data)\n",
    "        if but != record[\"Computer guessed\"]:\n",
    "            sheet.update_cell(row, 11, but)\n",
    "    except Exception as e:\n",
    "        print(\"Exception at row \" + str(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Although not everything is filled in correctly, about 80% of my transactions are now correctly labeled! It saved me a lot of time, was an interesting challenge, and makes the awesome Excel sheet way more usable now. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
